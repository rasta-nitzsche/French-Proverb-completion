{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556a1846",
   "metadata": {
    "id": "556a1846"
   },
   "source": [
    "In this task, we will achieve the completion of French proverbs. Our work will consist of fine-tuning an encoder transformer in order to complete  proverbs by applying the appropriate word. We will analyze the results obtained."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32db9b4b",
   "metadata": {
    "id": "32db9b4b"
   },
   "source": [
    "### Import the necessary modules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b42db401",
   "metadata": {
    "id": "b42db401"
   },
   "source": [
    "And prepare reading files functions. Here some necessary manipulations have been added for the test file in order to read dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550138d8",
   "metadata": {
    "id": "550138d8"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004dd79e",
   "metadata": {
    "id": "004dd79e"
   },
   "outputs": [],
   "source": [
    "def load_proverbs(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        raw_lines = f.readlines()\n",
    "    return [x.strip() for x in raw_lines]\n",
    "\n",
    "def load_tests(filename):\n",
    "    fp = open(filename, encoding='utf-8')\n",
    "    test_data = json.load(fp)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85c44a1",
   "metadata": {
    "id": "e85c44a1"
   },
   "outputs": [],
   "source": [
    "proverbs_fn = \"data_proverbes/proverbes.txt\"\n",
    "test1_fn = \"data_proverbes/test_proverbes.json\"\n",
    "\n",
    "corpus = load_proverbs(proverbs_fn)\n",
    "test = load_proverbs(test1_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a751fbe",
   "metadata": {
    "id": "1a751fbe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = ''.join(str(x) for x in test)\n",
    "\n",
    "t = a.split('},{')\n",
    "\n",
    "t[0] = t[0][2:]\n",
    "t[-1] = t[-1][:-2]\n",
    "\n",
    "for i in range(len(t)):\n",
    "    t[i] =  ast.literal_eval(\"{\" + t[i] + '}')\n",
    "    \n",
    "test = pd.DataFrame.from_dict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f85b809",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1f85b809",
    "outputId": "ad9216c8-7a6a-4879-fd9f-ae2671c26350",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bacda35b-cc3f-46d5-9ec9-86f9a5df7b14\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>choices</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beau mentir qui *** de loin</td>\n",
       "      <td>[vient, part, revient, programme]</td>\n",
       "      <td>vient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a beau *** qui vient de loin</td>\n",
       "      <td>[mentir, savoir, temps, dire]</td>\n",
       "      <td>mentir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>année de gelée, *** de blé</td>\n",
       "      <td>[année, absence, saison, mois]</td>\n",
       "      <td>année</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>après la pluie, le *** temps</td>\n",
       "      <td>[beau, bon, meilleur, mauvais]</td>\n",
       "      <td>beau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aux échecs, les *** sont les plus près des rois</td>\n",
       "      <td>[fous, joueurs, dames, femmes]</td>\n",
       "      <td>fous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bacda35b-cc3f-46d5-9ec9-86f9a5df7b14')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bacda35b-cc3f-46d5-9ec9-86f9a5df7b14 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bacda35b-cc3f-46d5-9ec9-86f9a5df7b14');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              test  \\\n",
       "0                    a beau mentir qui *** de loin   \n",
       "1                     a beau *** qui vient de loin   \n",
       "2                       année de gelée, *** de blé   \n",
       "3                     après la pluie, le *** temps   \n",
       "4  aux échecs, les *** sont les plus près des rois   \n",
       "\n",
       "                             choices solution  \n",
       "0  [vient, part, revient, programme]    vient  \n",
       "1      [mentir, savoir, temps, dire]   mentir  \n",
       "2     [année, absence, saison, mois]    année  \n",
       "3     [beau, bon, meilleur, mauvais]     beau  \n",
       "4     [fous, joueurs, dames, femmes]     fous  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e46e5ecc",
   "metadata": {
    "id": "e46e5ecc"
   },
   "source": [
    "# Without Fine-Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2892948e",
   "metadata": {
    "id": "2892948e"
   },
   "source": [
    "We chose the bert-base-french-europeana-cased model which is the French model of BERT and available on HuggingFace. We get a score of 55%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0001309",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0001309",
    "outputId": "be6a67e6-b119-4d9a-859c-7343589ce58f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-french-europeana-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-base-french-europeana-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "generator = pipeline(task=\"fill-mask\", model=model_checkpoint, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126e9dd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "126e9dd8",
    "outputId": "57126d11-6955-4f8a-daeb-3e6085f3d9ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5535714285714286"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for sentence, word in zip(list(test['test']), list(test['solution'])) :\n",
    "    sentence = sentence.replace(\"***\",\"[MASK]\")\n",
    "    results = generator(sentence)\n",
    "    target = [result['token_str'] for result in results]\n",
    "    if word in target :\n",
    "        score = score + 1\n",
    "        \n",
    "score / len(list(test['test']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7270c9b",
   "metadata": {
    "id": "a7270c9b"
   },
   "source": [
    "The results are promising, the French language is well captured but the proverbs use a rather particular sustained French which can give us these results (We will see this in detail in the analysis)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0853c597",
   "metadata": {
    "id": "0853c597"
   },
   "source": [
    "# Let's Fine-Tune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de94ed00",
   "metadata": {
    "id": "de94ed00"
   },
   "source": [
    "We will use the masked language model approach, we will use Bert's tokenizer and load the specialized model for MLM (**BertForMaskedLM**) from the previous French model (using the **from_pretrained** function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251e9cc3",
   "metadata": {
    "id": "251e9cc3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from transformers import BertTokenizer\n",
    "from transformers import LineByLineTextDataset\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0e243f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc0e243f",
    "outputId": "89d259e7-6477-4edf-db57-43ab8ab118f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-french-europeana-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-french-europeana-cased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"dbmdz/bert-base-french-europeana-cased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca933df",
   "metadata": {
    "id": "9ca933df"
   },
   "source": [
    "We will create the dataset from the proverbs data. We use **LineByLineTextDataset** because our text file contains separated lines which is more suitable for our work (instead of concatenating all the data). In addition, it allowed to obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72dc504",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d72dc504",
    "outputId": "d6c5fc5d-444a-45f5-c906-444af2b38236"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:121: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data_proverbes/proverbes.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "388ddaa0",
   "metadata": {
    "id": "388ddaa0"
   },
   "source": [
    "The data collator will be responsible for preparing the training and test data, it is also responsible for creating the mask for the MLM (because we choose a **DataCollatorForLanguageModeling**) with a probability of masking a word of 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c8ca5c",
   "metadata": {
    "id": "a6c8ca5c"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7c015e4",
   "metadata": {
    "id": "d7c015e4"
   },
   "source": [
    "Pre-training parameters (10 epochs only to avoid overfitting, the dataset is not very big either)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f11939df",
   "metadata": {
    "id": "f11939df"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./proverb_bert\",\n",
    "    # overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c851351",
   "metadata": {
    "id": "4c851351"
   },
   "source": [
    "Creating the Pytorch trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfe8f22",
   "metadata": {
    "id": "5cfe8f22"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ce5b225",
   "metadata": {
    "id": "5ce5b225"
   },
   "source": [
    "Pre training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34413dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "f34413dc",
    "outputId": "912b7bdb-62ea-4386-d31b-34906af2ea6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3108\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 490\n",
      "  Number of trainable parameters = 110650880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='490' max='490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [490/490 04:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=490, training_loss=1.7918042241310588, metrics={'train_runtime': 285.2451, 'train_samples_per_second': 108.959, 'train_steps_per_second': 1.718, 'total_flos': 710554212237312.0, 'train_loss': 1.7918042241310588, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d10dccbe",
   "metadata": {
    "id": "d10dccbe"
   },
   "source": [
    "Pushing the model to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "BpWq2DlS-jTi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "10759d87008b4495b711c248cb7a2d64",
      "0d304d32f546422f924cd6b755158039",
      "2688093362fd4dfa88450f2d7db3b123",
      "5df30d7ba11e41bbb605a8a689a819b0",
      "c4bf2d7727e54a41a9b63a61beda9859",
      "2165a8e1f5eb4e5cbd118302cc6235a7",
      "50f9564d13a2429daed4674fddbe7119",
      "ce031d92016145c7bbb454f82b33f355",
      "2f475c71cc7a493b884005b49fa1e19e",
      "b18570f5876d43cbb4ea90b02b1230de",
      "4a6c7a84aaf0441bbada22f94d6e69a2",
      "925400c421d94ba790db0f0abb50cf63",
      "08625ce6c1364ef9856d9457ae7ba900",
      "9da7dd1bc9084dd19b0799fae704f930",
      "ebeab8912cfc44578c630dada99685be",
      "60dcfcbb105e493b8c7ecf98412fbdc3",
      "2e094a16b2454a6b95f54a3ee10569d8"
     ]
    },
    "id": "BpWq2DlS-jTi",
    "outputId": "6eaff487-434c-4aad-9401-1f58c674cc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /root/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd28ac6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bd28ac6",
    "outputId": "e85efd1e-98c4-4b81-99c9-df6648bf8053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmp209glfrb/config.json\n",
      "Model weights saved in /tmp/tmp209glfrb/pytorch_model.bin\n",
      "Uploading the following files to rasta/proverbes-french-IFT-7022: pytorch_model.bin,config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rasta/proverbes-french-IFT-7022/commit/b5e5bc2889a24b0474adb60f8a6e2d427a8e628a', commit_message='Upload BertForMaskedLM', commit_description='', oid='b5e5bc2889a24b0474adb60f8a6e2d427a8e628a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"rasta/proverbes-french-IFT-7022\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "509aee3d",
   "metadata": {
    "id": "509aee3d"
   },
   "source": [
    "# Résults after pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac20086",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ac20086",
    "outputId": "3d597586-8f64-4706-936c-2a314984a1de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dbmdz--bert-base-french-europeana-cased/snapshots/b895c3cf291f7bf4c15639078a6bee0b3e272c5b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-french-europeana-cased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--dbmdz--bert-base-french-europeana-cased/snapshots/b895c3cf291f7bf4c15639078a6bee0b3e272c5b/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--dbmdz--bert-base-french-europeana-cased/snapshots/b895c3cf291f7bf4c15639078a6bee0b3e272c5b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dbmdz--bert-base-french-europeana-cased/snapshots/b895c3cf291f7bf4c15639078a6bee0b3e272c5b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-french-europeana-cased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--dbmdz--bert-base-french-europeana-cased/snapshots/b895c3cf291f7bf4c15639078a6bee0b3e272c5b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-french-europeana-cased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--rasta--proverbes-french-IFT-7022/snapshots/b5e5bc2889a24b0474adb60f8a6e2d427a8e628a/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rasta/proverbes-french-IFT-7022\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--rasta--proverbes-french-IFT-7022/snapshots/b5e5bc2889a24b0474adb60f8a6e2d427a8e628a/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"rasta/proverbes-french-IFT-7022\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--rasta--proverbes-french-IFT-7022/snapshots/b5e5bc2889a24b0474adb60f8a6e2d427a8e628a/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
      "\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at rasta/proverbes-french-IFT-7022.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-base-french-europeana-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model= \"rasta/proverbes-french-IFT-7022\"\n",
    "\n",
    "generator_pretrained = pipeline(task=\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8364b2e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8364b2e0",
    "outputId": "ad093fd7-fcf5-4972-b0c7-941a01fba4a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for sentence, word in zip(list(test['test']), list(test['solution'])) :\n",
    "    sentence = sentence.replace(\"***\",\"[MASK]\")\n",
    "    results = generator_pretrained(sentence)\n",
    "    target = [result['token_str'] for result in results]\n",
    "    if word in target :\n",
    "        score = score + 1\n",
    "        \n",
    "score / len(list(test['test']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7e7afc3",
   "metadata": {
    "id": "c7e7afc3"
   },
   "source": [
    "Result after Fine tuning: 85%. We observe an improvement in the results, which shows that the model has learned better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e0919cf",
   "metadata": {
    "id": "6e0919cf"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d8bd988",
   "metadata": {
    "id": "8d8bd988"
   },
   "source": [
    "The Fine-Tuned model obtains better results (55% vs 85%) because it has better learned the language of proverbs especially to predict end-of-sentence words. Without Fine-Tune, one obtains results which are coherent in terms of language, syntactically correct but which do not correspond to the context of the proverb. The following examples can demonstrate this phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4592a8c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4592a8c8",
    "outputId": "32c807bd-95f4-4177-ee07-f9b3d7977647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "quand la poire est mûre, elle [MASK]\n",
      "mot correct:  tombe\n",
      "mots prédit :  .\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "quand la poire est mûre, elle [MASK]\n",
      "mot correct:  tombe\n",
      "mots prédit :  tombe\n"
     ]
    }
   ],
   "source": [
    "sentence = 'quand la poire est mûre, elle [MASK]'\n",
    "word = \"tombe\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e6a60f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e6a60f9",
    "outputId": "0cfe9a3b-352a-457c-c2d3-ac6648fa2278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "à maison laide arbre [MASK]\n",
      "mot correct:  mort\n",
      "mots prédit :  .\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "à maison laide arbre [MASK]\n",
      "mot correct:  mort\n",
      "mots prédit :  mort\n"
     ]
    }
   ],
   "source": [
    "sentence = 'à maison laide arbre [MASK]'\n",
    "word = \"mort\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c269902",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c269902",
    "outputId": "77604019-46c8-4b45-ca07-b1c3d60a355d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "mieux vaut [MASK] que jamais\n",
      "mot correct:  tard\n",
      "mots prédit :  plus\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "mieux vaut [MASK] que jamais\n",
      "mot correct:  tard\n",
      "mots prédit :  tard\n"
     ]
    }
   ],
   "source": [
    "sentence = 'mieux vaut [MASK] que jamais'\n",
    "word = \"tard\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "214bf68c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "214bf68c",
    "outputId": "c693a6db-b551-4e99-a8bb-b804dbdcef52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "année de gelée, [MASK] de blé\n",
      "mot correct:  année\n",
      "mots prédit :  beaucoup\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "année de gelée, [MASK] de blé\n",
      "mot correct:  année\n",
      "mots prédit :  année\n"
     ]
    }
   ],
   "source": [
    "sentence = 'année de gelée, [MASK] de blé'\n",
    "word = \"année\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fd9b401",
   "metadata": {
    "id": "0fd9b401"
   },
   "source": [
    "Finally, some correct examples for both, which are generally to recognize the verb or especially auxiliaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83636d98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83636d98",
    "outputId": "8677b9eb-cbd6-44ad-cb5a-b20c40b67e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "a beau mentir qui [MASK] de loin\n",
      "mot correct:  vient\n",
      "mots prédit :  vient\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "a beau mentir qui [MASK] de loin\n",
      "mot correct:  vient\n",
      "mots prédit :  vient\n"
     ]
    }
   ],
   "source": [
    "sentence = 'a beau mentir qui [MASK] de loin'\n",
    "word = \"vient\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b18274de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b18274de",
    "outputId": "fb7e52b7-5ed8-4c6d-d159-9b82831918d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "ce que [MASK] veut, dieu le veut\n",
      "mot correct:  femme\n",
      "mots prédit :  femme\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "ce que [MASK] veut, dieu le veut\n",
      "mot correct:  femme\n",
      "mots prédit :  femme\n"
     ]
    }
   ],
   "source": [
    "sentence = 'ce que [MASK] veut, dieu le veut'\n",
    "word = \"femme\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74efaab5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74efaab5",
    "outputId": "70d977b7-e69f-43d9-927b-8f565404ea95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** SANS FINE TUNE *********************\n",
      "\n",
      "d'un sac [MASK] ne peut tirer deux moutures\n",
      "mot correct:  on\n",
      "mots prédit :  on\n",
      "\n",
      "********** AVEC FINE TUNE *********************\n",
      "\n",
      "d'un sac [MASK] ne peut tirer deux moutures\n",
      "mot correct:  on\n",
      "mots prédit :  on\n"
     ]
    }
   ],
   "source": [
    "sentence = \"d'un sac [MASK] ne peut tirer deux moutures\"\n",
    "word = \"on\"\n",
    "\n",
    "results = generator(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"********** SANS FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])\n",
    "    \n",
    "\n",
    "results = generator_pretrained(sentence)\n",
    "target = [result['token_str'] for result in results]\n",
    "\n",
    "print(\"\\n********** AVEC FINE TUNE *********************\\n\")\n",
    "print(sentence)\n",
    "print(\"mot correct: \",word)\n",
    "if word in target:\n",
    "    print(\"mots prédit : \", word)\n",
    "else :\n",
    "    print(\"mots prédit : \", target[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08625ce6c1364ef9856d9457ae7ba900": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d304d32f546422f924cd6b755158039": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce031d92016145c7bbb454f82b33f355",
      "placeholder": "​",
      "style": "IPY_MODEL_2f475c71cc7a493b884005b49fa1e19e",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "10759d87008b4495b711c248cb7a2d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d304d32f546422f924cd6b755158039",
       "IPY_MODEL_2688093362fd4dfa88450f2d7db3b123",
       "IPY_MODEL_5df30d7ba11e41bbb605a8a689a819b0",
       "IPY_MODEL_c4bf2d7727e54a41a9b63a61beda9859",
       "IPY_MODEL_2165a8e1f5eb4e5cbd118302cc6235a7"
      ],
      "layout": "IPY_MODEL_50f9564d13a2429daed4674fddbe7119"
     }
    },
    "2165a8e1f5eb4e5cbd118302cc6235a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60dcfcbb105e493b8c7ecf98412fbdc3",
      "placeholder": "​",
      "style": "IPY_MODEL_2e094a16b2454a6b95f54a3ee10569d8",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "2688093362fd4dfa88450f2d7db3b123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_b18570f5876d43cbb4ea90b02b1230de",
      "placeholder": "​",
      "style": "IPY_MODEL_4a6c7a84aaf0441bbada22f94d6e69a2",
      "value": ""
     }
    },
    "2e094a16b2454a6b95f54a3ee10569d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f475c71cc7a493b884005b49fa1e19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a6c7a84aaf0441bbada22f94d6e69a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50f9564d13a2429daed4674fddbe7119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "5df30d7ba11e41bbb605a8a689a819b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_925400c421d94ba790db0f0abb50cf63",
      "style": "IPY_MODEL_08625ce6c1364ef9856d9457ae7ba900",
      "value": true
     }
    },
    "60dcfcbb105e493b8c7ecf98412fbdc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "925400c421d94ba790db0f0abb50cf63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9da7dd1bc9084dd19b0799fae704f930": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b18570f5876d43cbb4ea90b02b1230de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4bf2d7727e54a41a9b63a61beda9859": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_9da7dd1bc9084dd19b0799fae704f930",
      "style": "IPY_MODEL_ebeab8912cfc44578c630dada99685be",
      "tooltip": ""
     }
    },
    "ce031d92016145c7bbb454f82b33f355": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebeab8912cfc44578c630dada99685be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
